{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "driving-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import string \n",
    "import nltk\n",
    "from collections import Counter\n",
    "import math\n",
    "import re\n",
    "\n",
    "from estnltk.taggers import VabamorfTagger\n",
    "from estnltk import Span, Layer\n",
    "from estnltk.tests import new_text\n",
    "from estnltk.converters import text_to_json, json_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "neither-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faili_info_salvestamine(filename):\n",
    "    global keskmised\n",
    "    \n",
    "    # Loob failinimed\n",
    "    ga_name = os.path.join(\"../etnc19_web_2019_morf_oletamisega/\", \".\".join(filename.split(\".\")[:-1]) + \"_morf_oletamisega.json\")\n",
    "    \n",
    "    andmed_name = os.path.join(\"../etnc19_web_2019_andmed/\", \".\".join(filename.split(\".\")[:-1]) + \"_andmed.json\")\n",
    "    \n",
    "    # Loeb failidest sisse tekstid ja metainfo\n",
    "    oletamisega = json_to_text(file=ga_name)\n",
    "    \n",
    "    # Väljastatavate andmete sõnastik\n",
    "    andmed = defaultdict(float)\n",
    "    \n",
    "    # Metainfost oluliste andmete meelde jätmine\n",
    "    andmed[\"emotikonide_arv\"] = oletamisega.meta[\"emotikonide_arv\"]\n",
    "    andmed[\"TTR\"] = oletamisega.meta[\"TTR\"]\n",
    "    andmed[\"käändsõnade_osaarv\"] = oletamisega.meta[\"käänduvate_lemmade_osaarv\"]\n",
    "    andmed[\"lemmapikkuse_osaarv\"] = oletamisega.meta[\"keskmine_lemma_pikkus\"]\n",
    "    \n",
    "    # Arvutab tajuverbide osaarvu kõikidest verbidest ja jätab meelde\n",
    "    andmed['tajuverbide_osaarv'] = tajuverbide_keskmine(oletamisega)\n",
    "    \n",
    "    # Loendab kokku sõnadesse kokku kleepunud kirjavahemärkide arvu\n",
    "    andmed['kokkukleepunud_kirjavahemärkide_arv'] = leia_kokkukleepunud_kirjavahemärgid(oletamisega)\n",
    "    \n",
    "    # Leiab verbide isikute protsendid (kui palju on 1., 2. ja 3. isik)\n",
    "    verbide_isikute_protsendid = verbide_isikute_osakaalud(oletamisega)\n",
    "    andmed['verbide_esimese_isiku_osaarv'] = verbide_isikute_protsendid[0]\n",
    "    andmed['verbide_teise_isiku_osaarv'] = verbide_isikute_protsendid[1]\n",
    "    andmed['verbide_kolmanda_isiku_osaarv'] = verbide_isikute_protsendid[2]\n",
    "    \n",
    "    # Leiab asesõnade isikute protsendid (kui palju on 1., 2. ja 3. isik)\n",
    "    asesonade_isikute_protsendid = asesonade_isikute_osakaalud(oletamisega)\n",
    "    andmed['asesõnade_esimese_isiku_osaarv'] = asesonade_isikute_protsendid[0]\n",
    "    andmed['asesõnade_teise_isiku_osaarv'] = asesonade_isikute_protsendid[1]\n",
    "    andmed['asesõnade_kolmanda_isiku_osaarv'] = asesonade_isikute_protsendid[2]\n",
    "    \n",
    "    # Leiab passiivi osakaalu ja jätab meelde\n",
    "    andmed['passiivi_osakaal'] = passiivi_osakaal(oletamisega)\n",
    "    \n",
    "    # Leiab nud-partitsiibi osakaalu ja jätab meelde\n",
    "    andmed['nud-partitsiibiga_verbide_osakaal'] = nud_osakaal(oletamisega)\n",
    "    \n",
    "    # Leiab kaudse kõneviisi osakaalu ja jätab meelde\n",
    "    andmed['kaudse_kõneviisi_osakaal'] = vat_osakaal(oletamisega)\n",
    "    \n",
    "    # Leiab, kui palju tekstist on väikese algustähega või läbinisti suur\n",
    "    valed_suurused = vale_tähesuurus_osakaal(oletamisega)\n",
    "    andmed['puuduva_suure_algustähega'] = valed_suurused[0]\n",
    "    andmed['läbinisti_suur'] = valed_suurused[1]\n",
    "    \n",
    "    # Leiab korduvate sõnade arvu\n",
    "    andmed['korduvate_sõnade_arv'] = korduvate_sõnade_arv(oletamisega)\n",
    "    \n",
    "    # Leiab korduvate kokkukleepunud \"juppide\" arvu\n",
    "    # nt silbid aga ka muud arbitraarsed kordused üle 2 tähe ja 3 korduse\n",
    "    andmed['korduvate_juppide_arv'] = leia_korduvad_jupid(oletamisega)\n",
    "    \n",
    "    andmed['leksikonides_esinevade_osaarv'] = sõnaloendi_osaarv(oletamisega)\n",
    "    \n",
    "    # Kirjutab metainfo tagasi faili edasiseks skoori arvutamiseks\n",
    "    with open(andmed_name, 'w', encoding=\"UTF-8\") as fw:\n",
    "        json.dump(andmed, fw, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aerial-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tajuverbide keskmise arvutamine\n",
    "def tajuverbide_keskmine(oletamisega):\n",
    "    all_verbs = 0\n",
    "    only_tajuverbs = 0\n",
    "\n",
    "    for lemma, postag in zip(oletamisega.lemma, oletamisega.partofspeech):\n",
    "        if \"V\" in postag:\n",
    "            all_verbs += 1\n",
    "            for lemmake in lemma:\n",
    "                if lemmake in tajuverbid:\n",
    "                    only_tajuverbs += 1\n",
    "    # Kui tekstis ei leidu verbe, tagastab -1\n",
    "    if all_verbs == 0:\n",
    "        return -1\n",
    "    return only_tajuverbs / float(all_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "demanding-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korduvate (mitte kokku kleepunud) sõnade leidmine\n",
    "def korduvate_sõnade_arv(oletamisega):\n",
    "    rx = re.compile(r\"(\\b\\w+\\b)(\\s+\\1)+\", re.IGNORECASE)\n",
    "    rxx = rx.findall(oletamisega.text)\n",
    "\n",
    "    return len(rxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "meaning-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kokkukleepunud kirjavahemärkide leidmine\n",
    "def leia_kokkukleepunud_kirjavahemärgid(oletamisega):\n",
    "    rx = re.compile(r'\\D\\s?[,.!?][^\\d\\s]')\n",
    "    rxx = rx.findall(oletamisega.text)\n",
    "    return len(rxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sunrise-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leiab sõnasisesed kordused\n",
    "def leia_korduvad_jupid(oletamisega):\n",
    "    rx = re.compile(r\"([a-zA-ZüÜõÕäÄöÖšŠžŽ])\\1{3,}|([a-zA-ZüÜõÕäÄöÖšŠžŽ]{2,})\\2{2,}\", re.IGNORECASE)\n",
    "    rxx = rx.findall(oletamisega.text)\n",
    "    return len(rxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collect-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esimese, teise ja kolmanda isiku osakaalu leidmine verbidest\n",
    "def verbide_isikute_osakaalud(oletamisega):\n",
    "    # Tunnuste lõpud, EstNLTK dokumentatsioonist\n",
    "    # Ei kordu omavahel\n",
    "    esi_tunnused = ['sime', 'me', 'nuksime', 'nuksin', 'gem', 'ksin', 'n', 'sin', 'ksime']\n",
    "    teine_tunnused = ['te', 'o', 'nuksite', 'd', 'site', 'ge', 'ksite']\n",
    "    kolmas_tunnused = ['s', 'gu', 'vad', 'b']\n",
    "    \n",
    "    # Loeb kokku isikute kaupa ja kõik isikud kokku\n",
    "    arv_koik = 0\n",
    "    arv_esimene = 0\n",
    "    arv_teine = 0\n",
    "    arv_kolmas = 0\n",
    "    \n",
    "    # Vaatab iga sõna analüüsi\n",
    "    for analysis in oletamisega.morph_analysis:\n",
    "        # Kui pole mitmese analüüsiga\n",
    "        if len(analysis.partofspeech) == 1:\n",
    "            pos = analysis.partofspeech[0]\n",
    "            # Kui tegu on verbiga\n",
    "            if pos == \"V\":\n",
    "                #Jätab meelde sõnalõpu\n",
    "                form = analysis.form[0]\n",
    "                # Vaatab, kas tunnus on loendis, ja suurendab vastavalt skoori\n",
    "                if form in esi_tunnused:\n",
    "                    arv_koik += 1\n",
    "                    arv_esimene += 1\n",
    "                    continue\n",
    "                # Vaatab, kas tunnus on loendis, ja suurendab vastavalt skoori\n",
    "                elif form in teine_tunnused:\n",
    "                    arv_koik += 1\n",
    "                    arv_teine += 1\n",
    "                    continue\n",
    "                # Vaatab, kas tunnus on loendis, ja suurendab vastavalt skoori\n",
    "                elif form in kolmas_tunnused:\n",
    "                    arv_koik += 1\n",
    "                    arv_kolmas += 1\n",
    "                    continue\n",
    "    # Kui tekstis ei leidu isikulisi verbe, tagastab -1\n",
    "    if arv_koik == 0:\n",
    "        return -1, -1, -1\n",
    "    # Tagastab kõik kolm osaarvu\n",
    "    return arv_esimene/arv_koik, arv_teine/arv_koik, arv_kolmas/arv_koik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sapphire-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esimese, teise ja kolmanda isiku osakaalu leidmine asesõnadest\n",
    "def asesonade_isikute_osakaalud(oletamisega):\n",
    "    # Loeb kokku isikute kaupa ja kõik isikud kokku\n",
    "    arv_koik = 0\n",
    "    arv_esimene = 0\n",
    "    arv_teine = 0\n",
    "    arv_kolmas = 0\n",
    "    \n",
    "    # Vaatab iga sõna analüüsi\n",
    "    for analysis in oletamisega.morph_analysis:\n",
    "        # Kui pole mitmese analüüsiga\n",
    "        if len(analysis.partofspeech) == 1:\n",
    "            pos = analysis.partofspeech[0]\n",
    "            # Kui tegu on asesõnaga\n",
    "            if pos == \"P\":\n",
    "                #Jätab meelde asesõna\n",
    "                lemma = analysis.lemma[0]\n",
    "                #Vaatab asesõna algvormi ja suurendab vastavat skoori\n",
    "                if lemma == 'mina':\n",
    "                    arv_koik += 1\n",
    "                    arv_esimene += 1\n",
    "                    continue\n",
    "                #Vaatab asesõna algvormi ja suurendab vastavat skoori\n",
    "                #Teietamine automaatselt sama, mis sinatamine (sina mitmuse analüüs)\n",
    "                elif lemma == 'sina':\n",
    "                    arv_koik += 1\n",
    "                    arv_teine += 1\n",
    "                    continue\n",
    "                #Vaatab asesõna algvormi ja suurendab vastavat skoori\n",
    "                elif lemma == 'tema':\n",
    "                    arv_koik += 1\n",
    "                    arv_kolmas += 1\n",
    "                    continue\n",
    "    # Kui tekstis ei leidu asesõnu, tagastab -1\n",
    "    if arv_koik == 0:\n",
    "        return -1, -1, -1\n",
    "    # Tagastab kõik kolm osaarvu\n",
    "    return arv_esimene/arv_koik, arv_teine/arv_koik, arv_kolmas/arv_koik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "subtle-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umbisikuliste verbide osakaalu leidmine tekstist\n",
    "def passiivi_osakaal(oletamisega):\n",
    "    # Tunnuste lõpud, EstNLTK dokumentatsioonist\n",
    "    tunnused = ['takse', 'ti', 'tav', 'tuks', 'tagu', 'tama', 'tud', 'tuvat', 'tavat', 'taks', 'ta']\n",
    "    \n",
    "    # Loeb kokku tunnuste kaupa ja kõik kokku\n",
    "    arv_koik = 0\n",
    "    arv_passiiv = 0\n",
    "    \n",
    "    # Vaatab iga sõna analüüsi\n",
    "    for analysis in oletamisega.morph_analysis:\n",
    "        # Kui pole mitmese analüüsiga\n",
    "        if len(analysis.partofspeech) == 1:\n",
    "            pos = analysis.partofspeech[0]\n",
    "            # Kui tegu on verbiga\n",
    "            if pos == \"V\":\n",
    "                #Jätab meelde sõnalõpu\n",
    "                form = analysis.form[0]\n",
    "                # Vaatab, kas tunnus on loendis, ja suurendab vastavalt skoori\n",
    "                if form in tunnused:\n",
    "                    arv_koik += 1\n",
    "                    arv_passiiv += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    arv_koik += 1\n",
    "        # Kui on mitmese analüüsiga\n",
    "        else:\n",
    "            leidub_passiivne = False\n",
    "            # Vaatab kõiki analüüse\n",
    "            # Kui vähemalt üks on passiivi analüüsiga\n",
    "            # Märgib kogu leiduva vormi passiivseks\n",
    "            for pos, form in zip(analysis.partofspeech, analysis.form):\n",
    "                if pos == \"V\":\n",
    "                    # Vaatab, kas tunnus on loendis, ja märgib, et järelikult on passiiviga\n",
    "                    if form in tunnused:\n",
    "                        leidub_passiivne = True\n",
    "                        break\n",
    "            \n",
    "            if leidub_passiivne:\n",
    "                arv_koik += 1\n",
    "                arv_passiiv += 1\n",
    "            else:\n",
    "                arv_koik += 1\n",
    "    # Kui tekstis ei leidu verbe, tagastab -1\n",
    "    if arv_koik == 0:\n",
    "        return -1\n",
    "    # Tagastab osaarvu\n",
    "    return arv_passiiv/arv_koik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "referenced-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nud-partitsiibiga verbide osakaalu leidmine tekstist\n",
    "def nud_osakaal(oletamisega):\n",
    "    # Tunnuste lõpud, EstNLTK dokumentatsioonist\n",
    "    tunnused = ['nud']\n",
    "    \n",
    "    # Loeb kokku tunnuste kaupa ja kõik kokku\n",
    "    arv_koik = 0\n",
    "    arv_tunnus = 0\n",
    "    \n",
    "    # Vaatab iga sõna analüüsi\n",
    "    for analysis in oletamisega.morph_analysis:\n",
    "        # Kui pole mitmese analüüsiga\n",
    "        if len(analysis.partofspeech) == 1:\n",
    "            pos = analysis.partofspeech[0]\n",
    "            # Kui tegu on verbiga\n",
    "            if pos == \"V\":\n",
    "                #Jätab meelde sõnalõpu\n",
    "                form = analysis.form[0]\n",
    "                # Vaatab, kas tunnus on loendis, ja suurendab vastavalt skoori\n",
    "                if form in tunnused:\n",
    "                    arv_koik += 1\n",
    "                    arv_tunnus += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    arv_koik += 1\n",
    "        # Kui on mitmese analüüsiga\n",
    "        else:\n",
    "            leidub_tunnusega = False\n",
    "            # Vaatab kõiki analüüse\n",
    "            # Kui vähemalt üks on passiivi analüüsiga\n",
    "            # Märgib kogu leiduva vormi passiivseks\n",
    "            for pos, form in zip(analysis.partofspeech, analysis.form):\n",
    "                if pos == \"V\":\n",
    "                    # Vaatab, kas tunnus on loendis, ja märgib, et järelikult on passiiviga\n",
    "                    if form in tunnused:\n",
    "                        leidub_tunnusega = True\n",
    "                        break\n",
    "            \n",
    "            if leidub_tunnusega:\n",
    "                arv_koik += 1\n",
    "                arv_tunnus += 1\n",
    "            else:\n",
    "                arv_koik += 1\n",
    "    # Kui tekstis ei leidu verbe, tagastab -1\n",
    "    if arv_koik == 0:\n",
    "        return -1\n",
    "    # Tagastab osaarvu\n",
    "    return arv_tunnus/arv_koik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pacific-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vat-partitsiibiga verbide osakaalu leidmine tekstist\n",
    "def vat_osakaal(oletamisega):\n",
    "    # Tunnuste lõpud, EstNLTK dokumentatsioonist\n",
    "    tunnused = ['vat']\n",
    "    \n",
    "    # Loeb kokku tunnuste kaupa ja kõik kokku\n",
    "    arv_koik = 0\n",
    "    arv_tunnus = 0\n",
    "    \n",
    "    # Vaatab iga sõna analüüsi\n",
    "    for analysis in oletamisega.morph_analysis:\n",
    "        # Kui pole mitmese analüüsiga\n",
    "        if len(analysis.partofspeech) == 1:\n",
    "            pos = analysis.partofspeech[0]\n",
    "            # Kui tegu on verbiga\n",
    "            if pos == \"V\":\n",
    "                #Jätab meelde sõnalõpu\n",
    "                form = analysis.form[0]\n",
    "                # Vaatab, kas tunnus on loendis, ja suurendab vastavalt skoori\n",
    "                if form in tunnused:\n",
    "                    arv_koik += 1\n",
    "                    arv_tunnus += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    arv_koik += 1\n",
    "        # Kui on mitmese analüüsiga\n",
    "        else:\n",
    "            leidub_tunnusega = False\n",
    "            # Vaatab kõiki analüüse\n",
    "            # Kui vähemalt üks on passiivi analüüsiga\n",
    "            # Märgib kogu leiduva vormi passiivseks\n",
    "            for pos, form in zip(analysis.partofspeech, analysis.form):\n",
    "                if pos == \"V\":\n",
    "                    # Vaatab, kas tunnus on loendis, ja märgib, et järelikult on passiiviga\n",
    "                    if form in tunnused:\n",
    "                        leidub_tunnusega = True\n",
    "                        break\n",
    "            \n",
    "            if leidub_tunnusega:\n",
    "                arv_koik += 1\n",
    "                arv_tunnus += 1\n",
    "            else:\n",
    "                arv_koik += 1\n",
    "    # Kui tekstis ei leidu verbe, tagastab -1\n",
    "    if arv_koik == 0:\n",
    "        return -1\n",
    "    # Tagastab osaarvu\n",
    "    return arv_tunnus/arv_koik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "worthy-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vale_tähesuurus_osakaal(oletamisega):\n",
    "    vale_väike = 0\n",
    "    ainult_suur = 0\n",
    "    # Kõikide sõnade arv (ignoreerib kirjavahemärke)\n",
    "    kõik_arv = 0\n",
    "\n",
    "    # Vaatab iga lauset tekstis ükshaaval\n",
    "    for sentence in oletamisega.sentences:\n",
    "        kõik_arv += 1\n",
    "        # Vaatab lause esimest sõna eraldi\n",
    "        # Kas esimene sõna on täis väiketähed või täis suurtähed\n",
    "        if sentence.words[0].text.islower():\n",
    "            vale_väike += 1\n",
    "        elif sentence.words[0].text.isupper():\n",
    "            # Vaatab, et ei oleks ühe tähe suurune\n",
    "            if len(sentence.words[0].text) > 1:\n",
    "                ainult_suur += 1\n",
    "        # Vaatab iga ülejäänud sõna lauses\n",
    "        for word in sentence.words[1:]:\n",
    "            # Kui sõna on ühe tähe pikkune või ainult kirjavahemärgid, jätab selle sõna vahele\n",
    "            if len(word.text) == 1 or all(char in string.punctuation for char in word.text):\n",
    "                continue\n",
    "            kõik_arv += 1\n",
    "            # Vaatab iga sõna, kas on vaid suurtähed\n",
    "            if word.text.isupper():\n",
    "                # Vaatab, et ei oleks lühendi analüüsiga\n",
    "                lyhend = False\n",
    "                if 'Y' not in word.morph_analysis.partofspeech:\n",
    "                    ainult_suur += 1\n",
    "                    \n",
    "    # Kui tekstis ei sõnu, tagastab -1\n",
    "    if kõik_arv == 0:\n",
    "        return -1, -1\n",
    "    return vale_väike/kõik_arv, ainult_suur/kõik_arv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9346d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sõnaloendi_osaarv(oletamisega):\n",
    "    kokku = len(oletamisega.words)\n",
    "    loendis = 0\n",
    "    \n",
    "    for word in oletamisega.words:\n",
    "        sona = word.text.lower()\n",
    "        lemmad = word.lemma\n",
    "        if sona in sõnaloend:\n",
    "            loendis += 1\n",
    "        else:\n",
    "            for lemma in lemmad:\n",
    "                if lemma.lower() in sõnaloend:\n",
    "                    loendis += 1\n",
    "                    break\n",
    "        \n",
    "    return loendis/kokku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24d0b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sõnaloend = None\n",
    "\n",
    "with open(\"../Loendid/Leksikonid/koos.txt\", \"r\", encoding=\"UTF-8\") as fr:\n",
    "    sõnaloend = [i.strip().lower() for i in fr.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0322165",
   "metadata": {},
   "outputs": [],
   "source": [
    "tajuverbid = None\n",
    "\n",
    "with open(\"../Loendid/tajuverbid/wordnet_tajuverbid.txt\", \"r\", encoding = \"utf8\") as fr:\n",
    "    lines = fr.readlines()\n",
    "    tajuverbid = [verb.strip() for verb in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "handed-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algse kausta nimi, võtab sealt algsed failinimed, ei loe neid faile sisse\n",
    "source = \"../etnc19_web_2019_100000/\"\n",
    "\n",
    "os.makedirs(os.path.dirname(\"../etnc19_web_2019_andmed/\"), exist_ok=True)\n",
    "\n",
    "with open(\"keskmised.json\", \"r\", encoding = \"UTF-8\") as fr:\n",
    "    keskmised = json.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "artistic-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avab järjest kõik failid algkaustas\n",
    "for file in [f for f in os.listdir(source)]:\n",
    "    # Arvutab faili kohta info\n",
    "    faili_info_salvestamine(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
